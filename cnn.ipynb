{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below. \n",
    "\n",
    "<img src=\"images/conv_nn.png\" style=\"width:350px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notation**:\n",
    "- Superscript $[l]$ denotes an object of the $l^{th}$ layer. \n",
    "    - Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.\n",
    "\n",
    "\n",
    "- Superscript $(i)$ denotes an object from the $i^{th}$ example. \n",
    "    - Example: $x^{(i)}$ is the $i^{th}$ training example input.\n",
    "    \n",
    "    \n",
    "- Subscript $i$ denotes the $i^{th}$ entry of a vector.\n",
    "    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$, assuming this is a fully connected (FC) layer.\n",
    "    \n",
    "    \n",
    "- $n_H$, $n_W$ and $n_C$ denote respectively the height, width and number of channels of a given layer. If you want to reference a specific layer $l$, you can also write $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$. \n",
    "- $n_{H_{prev}}$, $n_{W_{prev}}$ and $n_{C_{prev}}$ denote respectively the height, width and number of channels of the previous layer. If referencing a specific layer $l$, this could also be denoted $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of the Assignment\n",
    "\n",
    "We will be implementing the following:\n",
    "\n",
    "- Convolution functions, including:\n",
    "    - Zero Padding\n",
    "    - Convolve window \n",
    "    - Convolution forward\n",
    "    - Convolution backward (optional)\n",
    "- Pooling functions, including:\n",
    "    - Pooling forward\n",
    "    - Create mask \n",
    "    - Distribute value\n",
    "    - Pooling backward (optional)\n",
    "    \n",
    "This notebook will implement these functions from scratch in `numpy` as we did before. Then, we will use the TensorFlow equivalents of these functions to build the following model:\n",
    "\n",
    "<img src=\"images/model.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "**Note**: For every forward function, there is a corresponding backward equivalent. Hence, at every forward step module we will store some parameters in a cache. These parameters are used to compute gradients during backpropagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Padding\n",
    "\n",
    "Zero-padding adds zeros around the border of an image:\n",
    "\n",
    "<center><img src=\"images/PAD.png\" style=\"width:600px;height:400px;\"></center>\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><b>Zero-Padding</b><br> Image (3 channels, RGB) with a padding of 2. </center></caption></font>\n",
    "\n",
    "\n",
    "The main benefits of padding are:\n",
    "\n",
    "- It allows to use a CONV layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the \"same\" convolution, in which the height/width is exactly preserved after one layer. \n",
    "\n",
    "- It keeps more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels at the edges of an image.\n",
    "\n",
    "### Zero_pad\n",
    "Pads all the images of a batch of examples X with zeros with [np.pad](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), \n",
    "                   mode='constant', constant_values = (0,0))\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Step of Convolution \n",
    "\n",
    "In this part, implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which: \n",
    "\n",
    "- Takes an input volume \n",
    "- Applies a filter at every position of the input\n",
    "- Outputs another volume (usually of different size)\n",
    "\n",
    "<center><img src=\"images/Convolution_schematic.gif\" style=\"width:500px;height:300px;\"></center>\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 2</b> </u> <b>Convolution operation</b><br> with a filter of 3x3 and a stride of 1 (stride = amount you move the window each time you slide) </font></center></caption>\n",
    "\n",
    "In a computer vision application, each value in the matrix on the left corresponds to a single pixel value. You convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias. We will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output. \n",
    "\n",
    "Later we'll apply this function to multiple positions of the input to implement the full convolutional operation. \n",
    "    \n",
    "### Conv_single_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    Z = np.sum(s)\n",
    "    Z += float(b)\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_matrix(nh):\n",
    "\n",
    "    matrix = [[1, 0, -1] for _ in range(0, nh)]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[30,  0, 10],\n",
       "        [30,  0, 10],\n",
       "        [30,  0, 10]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_input = [[ 30, 0, 10] for _ in range(0,  3)]\n",
    "A = np.matrix(A_input)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1,  0, -1],\n",
       "        [ 1,  0, -1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "matrix_filter = initialize_matrix(2)\n",
    "filter = np.matrix(matrix_filter)\n",
    "\n",
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m             output[i, j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmultiply(sub_matrix, \u001b[38;5;28mfilter\u001b[39m))\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m---> 18\u001b[0m \u001b[43mforward_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m, in \u001b[0;36mforward_prop\u001b[0;34m(A, filter)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_dim):\n\u001b[1;32m     13\u001b[0m         sub_matrix \u001b[38;5;241m=\u001b[39m A[i:i\u001b[38;5;241m+\u001b[39mnF, j:j\u001b[38;5;241m+\u001b[39mnF]\n\u001b[0;32m---> 14\u001b[0m         output[i, j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2) (2,3) "
     ]
    }
   ],
   "source": [
    "def forward_prop(A, filter):\n",
    "    \n",
    "    nA = A.shape[0]\n",
    "    nF = filter.shape[0]\n",
    "\n",
    "    # Matriz para armazenar o resultado\n",
    "    output_dim = nA - nF + 1\n",
    "    output = np.zeros((output_dim, output_dim))\n",
    "\n",
    "    # Aplicando o filtro na matriz A\n",
    "    for i in range(output_dim):\n",
    "        for j in range(output_dim):\n",
    "            sub_matrix = A[i:i+nF, j:j+nF]\n",
    "            output[i, j] = np.sum(np.multiply(sub_matrix, filter))\n",
    "\n",
    "    return output\n",
    "\n",
    "forward_prop(A, filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0 10]]\n",
      "[[30  0 10]]\n",
      "[[30  0 10]]\n"
     ]
    }
   ],
   "source": [
    "A_ = A[:filter.shape[1]]\n",
    "for row in A_:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_prop(A, filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convulational_layer(A_input, nh, nw, np):\n",
    "    \n",
    "    np.matrix(nh, nw)\n",
    "\n",
    "    np.w\n",
    "    \n",
    "    for c in A_input:\n",
    "        c \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
